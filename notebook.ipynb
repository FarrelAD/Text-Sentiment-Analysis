{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/farrelad/text-sentiment-analysis?scriptVersionId=219867776\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Install necessary dependency","metadata":{}},{"cell_type":"code","source":"%pip install pandas numpy scikit-learn nltk datasets joblib --quiet","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-01-30T03:51:06.689016Z","iopub.execute_input":"2025-01-30T03:51:06.689382Z","iopub.status.idle":"2025-01-30T03:51:11.024182Z","shell.execute_reply.started":"2025-01-30T03:51:06.689352Z","shell.execute_reply":"2025-01-30T03:51:11.022837Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"imdb\")\n\ndf = dataset[\"train\"].to_pandas()\n\ndf = df.rename(columns={\"text\": \"review\", \"label\": \"sentiment\"})\n\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:47:32.142218Z","iopub.execute_input":"2025-01-30T03:47:32.142626Z","iopub.status.idle":"2025-01-30T03:47:35.946702Z","shell.execute_reply.started":"2025-01-30T03:47:32.142595Z","shell.execute_reply":"2025-01-30T03:47:35.945553Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                              review  sentiment\n0  I rented I AM CURIOUS-YELLOW from my video sto...          0\n1  \"I Am Curious: Yellow\" is a risible and preten...          0\n2  If only to avoid making this type of film in t...          0\n3  This film was probably inspired by Godard's Ma...          0\n4  Oh, brother...after hearing about this ridicul...          0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Split data","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['review'], df['sentiment'], test_size=0.2, random_state=42\n)","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:47:38.640397Z","iopub.execute_input":"2025-01-30T03:47:38.640844Z","iopub.status.idle":"2025-01-30T03:47:39.252774Z","shell.execute_reply.started":"2025-01-30T03:47:38.640813Z","shell.execute_reply":"2025-01-30T03:47:39.251609Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Text Preprocessing","metadata":{}},{"cell_type":"code","source":"import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\nnltk.download('stopwords')\nnltk.download('punkt')\n\nstop_words = set(stopwords.words('english'))\n\ndef preprocess_text(text):\n    text = text.lower()\n    text = re.sub(r'<[^>]+>', '', text)\n    text = re.sub(r'[^a-z\\s]', '', text)\n    words = word_tokenize(text)\n    words = [word for word in words if word not in stop_words]\n    return \" \".join(words)\n\ntrain_texts = train_texts.apply(preprocess_text)\ntest_texts = test_texts.apply(preprocess_text)\n\nprint(train_texts[:5])","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:47:43.977215Z","iopub.execute_input":"2025-01-30T03:47:43.977881Z","iopub.status.idle":"2025-01-30T03:48:08.139911Z","shell.execute_reply.started":"2025-01-30T03:47:43.977845Z","shell.execute_reply":"2025-01-30T03:48:08.138758Z"},"trusted":true},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n23311    borrowed movie despite extremely low rating wa...\n23623    unexpected accident killed inexperienced climb...\n1020     summer blockbuster hit baseketball one movies ...\n12645    scarcely imagine better movie thishey go chick...\n1533     still famous decadent actor morgan freeman fil...\nName: review, dtype: object\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Convert Text to Vectors","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer(max_features=5000)\nX_train = vectorizer.fit_transform(train_texts)\nX_test = vectorizer.transform(test_texts)\n\nprint(X_train.shape)","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:48:29.346111Z","iopub.execute_input":"2025-01-30T03:48:29.346517Z","iopub.status.idle":"2025-01-30T03:48:32.685492Z","shell.execute_reply.started":"2025-01-30T03:48:29.346483Z","shell.execute_reply":"2025-01-30T03:48:32.684587Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(20000, 5000)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Training Model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nmodel = LogisticRegression()\nmodel.fit(X_train, train_labels)\n\ny_pred = model.predict(X_test)\n\naccuracy = accuracy_score(test_labels, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:48:35.746974Z","iopub.execute_input":"2025-01-30T03:48:35.747451Z","iopub.status.idle":"2025-01-30T03:48:36.22496Z","shell.execute_reply.started":"2025-01-30T03:48:35.74739Z","shell.execute_reply":"2025-01-30T03:48:36.223812Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Accuracy: 0.88\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def predict_sentiment(text):\n    processed_text = preprocess_text(text)\n    vectorized_text = vectorizer.transform([processed_text])\n    prediction = model.predict(vectorized_text)[0]\n    return \"Positive\" if prediction == 1 else \"Negative\"","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:48:41.059386Z","iopub.execute_input":"2025-01-30T03:48:41.059778Z","iopub.status.idle":"2025-01-30T03:48:41.065291Z","shell.execute_reply.started":"2025-01-30T03:48:41.05975Z","shell.execute_reply":"2025-01-30T03:48:41.063716Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import ipywidgets as widgets\n\noutput = widgets.Output()\n\ntext_input = widgets.Text(\n    description='Input Text:', \n    placeholder='Type something here'\n)\n\nsubmit_btn = widgets.Button(\n    description='Submit',\n    button_style='info'\n)\n\ndef process_input(_):\n    text = text_input.value\n\n    with output:\n        output.clear_output()\n        print(predict_sentiment(text))\n\nsubmit_btn.on_click(process_input)\n\nlayout = widgets.VBox([\n    text_input,\n    submit_btn,\n    output\n])\n\nlayout","metadata":{"execution":{"iopub.status.busy":"2025-01-30T03:48:44.134372Z","iopub.execute_input":"2025-01-30T03:48:44.134815Z","iopub.status.idle":"2025-01-30T03:48:44.153097Z","shell.execute_reply.started":"2025-01-30T03:48:44.134783Z","shell.execute_reply":"2025-01-30T03:48:44.151921Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"VBox(children=(Text(value='', description='Input Text:', placeholder='Type something here'), Button(button_styâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f2baaa1ff054b9dbc3305fbc116553f"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# Deployment","metadata":{}},{"cell_type":"code","source":"import joblib\n\njoblib.dump(model, 'sentiment_model.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T03:51:38.657136Z","iopub.execute_input":"2025-01-30T03:51:38.657559Z","iopub.status.idle":"2025-01-30T03:51:38.666644Z","shell.execute_reply.started":"2025-01-30T03:51:38.657524Z","shell.execute_reply":"2025-01-30T03:51:38.665527Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['sentiment_model.pkl']"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"## Create pipeline to bundle together model and vectorizer","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nimport joblib\n\npipeline = Pipeline([\n    ('vectorizer', vectorizer),\n    ('model', model)\n])\n\n\njoblib.dump(pipeline, 'sentiment_analysis_pipeline.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T04:07:34.323644Z","iopub.execute_input":"2025-01-30T04:07:34.323998Z","iopub.status.idle":"2025-01-30T04:07:34.865986Z","shell.execute_reply.started":"2025-01-30T04:07:34.323971Z","shell.execute_reply":"2025-01-30T04:07:34.865112Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['sentiment_analysis_pipeline.pkl']"},"metadata":{}}],"execution_count":15}]}